# AI-Researcher

# Autonomous Multi-Agent AI Research Lab

---

**Revolutionize AI/ML research with a fully autonomous, agent-driven local system**  
_Beat benchmarks. Invent new models. Automate experiments. All with minimal human oversight._

---

## ğŸš€ Project Overview

The Autonomous Multi-Agent AI Research Lab is a modular, locally running, next-generation research platform that combines the **creativity and intelligence of LLMs** with rigorous, automated experiment orchestration.  
It enables research teams, organizations, or solo researchers to rapidly:

- Generate **novel research ideas**
- Autonomously write and debug code
- Run and track experiments safely
- Evaluate results and produce publication-ready reports

All of this is managed by specialized AI agents, with robust approval and correction workflows, and full resource managementâ€”**no constant human babysitting required**.

---

## ğŸ§  Core Features

- **Multi-Agent Architecture:** Specialized agents for creative ideation, code generation, experiment orchestration, and results evaluation.
- **Hybrid LLM Support:** Combine state-of-the-art cloud LLMs (e.g., GPT-4o via OpenAI API) with powerful local LLMs (e.g., Llama-3, DeepSeek Coder).
- **Robust Experiment Management:** All code, models, logs, and results are stored on diskâ€”never lost, always reproducible.
- **Approval & Correction Loops:** Every big step is checked for ambiguity, errors, and benchmark alignment before proceeding.
- **Full Resource Safety:** Agents and experiments alternate GPU/CPU usage so resource conflicts are impossible.
- **Configurable, Extensible, Transparent:** All parameters, agents, and models are swappable via configs and modular code.

---

## ğŸ—ï¸ Architecture & Workflow

### **System Agents**

| Agent           | Role                                                  | Model Example                    |
|-----------------|-------------------------------------------------------|----------------------------------|
| **Idea Agent**  | Proposes new research/model ideas; scans SOTA         | GPT-4o (API), Llama-3-70B        |
| **Manager Agent** | Reviews, approves, plans, enforces benchmarks       | Llama-3-8B, Mistral              |
| **Coder Agent** | Writes, debugs, and runs code for experiments         | DeepSeek Coder, CodeLlama, StarCoder-2, OpenDevin |
| **Reviewer Agent** | Evaluates results, visualizes, drafts reports      | Llama-3-8B, GPT-4o               |

### **High-Level Workflow**

1. **Prompt**: You enter a research goal (e.g., "Beat UNet on ACDC dataset").
2. **Ideation**: Idea Agent (cloud or local LLM) proposes a model or technique.
3. **Approval**: Manager Agent checks clarity, novelty, and feasibility.
4. **Development**: Coder Agent generates code, handles errors, and runs the experiment.
5. **Execution**: Experiment runs in isolation, freeing resources on completion.
6. **Review**: Reviewer Agent analyzes results, generates plots/reports, and recommends next steps.
7. **Iteration**: If needed, agents loop, retry, or escalate for human review.

**All actions, code, and results are stored on disk and tracked in memory for full transparency and safety.**

---

## ğŸ—‚ï¸ Repo Structure

```plaintext
autonomous-research-lab/
â”‚
â”œâ”€â”€ agents/                  # Agent logic: idea, coder, manager, reviewer
â”‚   â”œâ”€â”€ idea_agent.py
â”‚   â”œâ”€â”€ coder_agent.py
â”‚   â”œâ”€â”€ manager_agent.py
â”‚   â”œâ”€â”€ reviewer_agent.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ llm_backends/            # LLM servers/wrappers: local (vLLM/LMDeploy) and cloud (OpenAI API)
â”‚   â”œâ”€â”€ serve_llama.py
â”‚   â”œâ”€â”€ serve_coder.py
â”‚   â”œâ”€â”€ client.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ orchestrator/            # Main workflow control, scheduling, and agent task management
â”‚   â”œâ”€â”€ scheduler.py
â”‚   â”œâ”€â”€ task_queue.py
â”‚   â”œâ”€â”€ process_manager.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ experiment/              # Handles experiment execution, logs, data, envs, results
â”‚   â”œâ”€â”€ runner.py
â”‚   â”œâ”€â”€ result_parser.py
â”‚   â”œâ”€â”€ data_handler.py
â”‚   â”œâ”€â”€ env_manager.py
â”‚   â”œâ”€â”€ job_templates/
â”‚   â”‚   â””â”€â”€ pytorch_train_template.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ memory/                  # Persistent experiment logs, agent memory, retrieval-augmented DB
â”‚   â”œâ”€â”€ db.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ storage/                 # All experiment outputs: code, models, logs, results (disk-based)
â”‚   â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ .gitignore
â”‚
â”œâ”€â”€ configs/                 # YAML/JSON configs: agents, LLMs, experiments, datasets, workspace
â”‚   â”œâ”€â”€ agents.yaml
â”‚   â”œâ”€â”€ llm_servers.yaml
â”‚   â”œâ”€â”€ experiment.yaml
â”‚   â”œâ”€â”€ datasets.yaml
â”‚   â””â”€â”€ workspace.yaml
â”‚
â”œâ”€â”€ ui/                      # (Optional) Web dashboard or CLI interface
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ scripts/                 # Launch, clean, backup, and utility scripts
â”‚   â”œâ”€â”€ launch_agents.sh
â”‚   â”œâ”€â”€ run_experiment.sh
â”‚   â”œâ”€â”€ clean_gpu.sh
â”‚   â”œâ”€â”€ backup_db.sh
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ tests/                   # Unit/integration tests for robustness and reliability
â”‚   â”œâ”€â”€ test_agents.py
â”‚   â”œâ”€â”€ test_runner.py
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ Dockerfile               # (Optional) For portable, reproducible deployment
â”œâ”€â”€ README.md                # (You are here!)
â””â”€â”€ LICENSE
